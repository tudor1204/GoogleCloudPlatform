{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install **kubectl** and the **Google Cloud SDK** with the necessary authentication plugin for Google Kubernetes Engine (GKE)."
      ],
      "metadata": {
        "id": "ZIanN1T4tiGW"
      },
      "id": "ZIanN1T4tiGW"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
        "sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n",
        "apt-get update && apt-get install apt-transport-https ca-certificates gnupg\n",
        "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
        "apt-get update && sudo apt-get install google-cloud-cli-gke-gcloud-auth-plugin"
      ],
      "metadata": {
        "id": "7z5UsvCItlFd"
      },
      "id": "7z5UsvCItlFd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace** \\<CLUSTER_NAME> with your cluster name, e.g. pgvector-re-cluster. Retrieve the GKE cluster's credentials using the gcloud command."
      ],
      "metadata": {
        "id": "TfzQ43WCtrLf"
      },
      "id": "TfzQ43WCtrLf"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "export KUBERNETES_CLUSTER_NAME=<CLUSTER_NAME>\n",
        "gcloud container clusters get-credentials $KUBERNETES_CLUSTER_NAME --region $GOOGLE_CLOUD_REGION"
      ],
      "metadata": {
        "id": "AZEJriU_trwM"
      },
      "id": "AZEJriU_trwM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset from Git."
      ],
      "metadata": {
        "id": "9vKcG2I0uMq0"
      },
      "id": "9vKcG2I0uMq0"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "export DATASET_PATH=https://raw.githubusercontent.com/epam/kubernetes-engine-samples/recommendation-engine/ai-ml/recommendation-engine/manifests/02-notebook/dataset.json\n",
        "curl -s -LO $DATASET_PATH"
      ],
      "metadata": {
        "id": "H83yi6cZuOJ3"
      },
      "id": "H83yi6cZuOJ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an .env file with environment variables required for connecting to Postgresql in a Kubernetes cluster."
      ],
      "metadata": {
        "id": "zC8X6x_luh1Z"
      },
      "id": "zC8X6x_luh1Z"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "echo POSTGRES_ENDPOINT=$(kubectl get pod -l cnpg.io/instanceRole=primary -n pg-ns -o=jsonpath=\"{.items[0].status.podIP}\") > .env\n",
        "echo DATABASE_NAME=app >> .env\n",
        "echo DBUSERNAME=$(kubectl get secret gke-pg-cluster-superuser -n pg-ns --template={{.data.username}} | base64 -d) >> .env\n",
        "echo DBPASSWORD=$(kubectl get secret gke-pg-cluster-superuser -n pg-ns --template={{.data.password}} | base64 -d) >> .env"
      ],
      "metadata": {
        "id": "Xl0BJtcKuqav"
      },
      "id": "Xl0BJtcKuqav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required python libraries:"
      ],
      "metadata": {
        "id": "_B0ICEE7vS8N"
      },
      "id": "_B0ICEE7vS8N"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade-strategy only-if-needed python-dotenv psycopg-binary psycopg langchain langchain-postgres langchain-community langchain-google-vertexai jq"
      ],
      "metadata": {
        "id": "2RilM35KvTeN"
      },
      "id": "2RilM35KvTeN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import python libraries:"
      ],
      "metadata": {
        "id": "uAxbpVKBvf-6"
      },
      "id": "uAxbpVKBvf-6"
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain_postgres.vectorstores import PGVector\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.prompts import format_document"
      ],
      "metadata": {
        "id": "Cm_adRRNvgiD"
      },
      "id": "Cm_adRRNvgiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and parse the dataset, using the JSON loader and retrieving only specific fields: category, description, gender, brand and color."
      ],
      "metadata": {
        "id": "3Y0OMkWfZtXr"
      },
      "id": "3Y0OMkWfZtXr"
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata_func(record: dict, metadata: dict) -> dict:\n",
        "    metadata[\"category\"] = record.get(\"category\")\n",
        "    metadata[\"description\"] = record.get(\"description\")\n",
        "    metadata[\"gender\"] = record.get(\"gender\")\n",
        "    metadata[\"brand\"] = record.get(\"brand\")\n",
        "    metadata[\"color\"] = \"\".join( c for c in record.get(\"color\") if c not in \"[]'\" )\n",
        "    return metadata\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path='/content/dataset.json',\n",
        "    jq_schema='.[]',\n",
        "    content_key='title',\n",
        "    metadata_func=metadata_func)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "NlWMw0OFwPVC"
      },
      "id": "NlWMw0OFwPVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the prompt templates, first one to interact with Gemini, and second to transform jsons into strings. Define the function to merge multiple found items from the database into one multiline string."
      ],
      "metadata": {
        "id": "w-duuLPRaMHC"
      },
      "id": "w-duuLPRaMHC"
    },
    {
      "cell_type": "code",
      "source": [
        "llm_prompt_template = PromptTemplate.from_template(\"\"\"\n",
        "    You're a helpful assistant who can recommend things in addition to those already chosen.\n",
        "    Already chosen item:\n",
        "    {chosen_item}\n",
        "\n",
        "    Available items:\n",
        "    {available_items}\n",
        "\n",
        "    Please check all available items and find the {max_recommendations} most suitable item or items for the chosen one.\n",
        "    Try to ensure that the recommended item or items will match the brand, color and purpose well.\n",
        "    Your answer should contain the chosen item, the recommended and the example how to use them all together.\n",
        "    Generate a draft response using the selected information.\n",
        "    It should be easy to understand your answer. Start your answer with the phrase: \"For <chosen_item> I would recommend <recommended>:\"\n",
        "    Don't forget to mention all {max_recommendations} recommendations.\n",
        "    Keep your answer to a four or five sentences if possible. If not - try to keep the answer short.\n",
        "    Generate your final response after adjusting it to increase accuracy and relevance.\n",
        "    Now only show your final response!\"\"\")\n",
        "\n",
        "data_format_prompt_template = PromptTemplate.from_template(\"| {page_content} | Category: {category} | Color: {color} | Gender: {gender} | Brand: {brand} | Description: {description} |\\n\")\n",
        "\n",
        "def format_data(documents):\n",
        "    result=\"\"\n",
        "    for doc in documents:\n",
        "        result += format_document(doc, data_format_prompt_template)\n",
        "    return result"
      ],
      "metadata": {
        "id": "BWv9pry1wXoN"
      },
      "id": "BWv9pry1wXoN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare two models from the Vertex AI model garden: Gecko (vector embedding model) and Gemini Flash (lightweight version of Gemini Pro)."
      ],
      "metadata": {
        "id": "xqln5NAxa3Z5"
      },
      "id": "xqln5NAxa3Z5"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = VertexAIEmbeddings(\"textembedding-gecko@latest\")\n",
        "llm = VertexAI(model_name=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "-qLZVvvPwen-"
      },
      "id": "-qLZVvvPwen-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load environment variables from the .env file, establish a connection to a PostgreSQL database and upload data from the dataset."
      ],
      "metadata": {
        "id": "eLIVop7KZj24"
      },
      "id": "eLIVop7KZj24"
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
        "    driver=\"psycopg\",\n",
        "    host=os.environ.get(\"POSTGRES_ENDPOINT\"),\n",
        "    port=5432,\n",
        "    database=os.environ.get(\"DATABASE_NAME\"),\n",
        "    user=os.environ.get(\"DBUSERNAME\"),\n",
        "    password=os.environ.get(\"DBPASSWORD\"),\n",
        ")\n",
        "db = PGVector.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=data,\n",
        "    collection_name=\"products\",\n",
        "    connection=CONNECTION_STRING,\n",
        ")"
      ],
      "metadata": {
        "id": "kKW0GME5w0d0"
      },
      "id": "kKW0GME5w0d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your preferences to use it in recommendation searches, or keep the variables empty to ignore them. For example, recommended things should be black and produced by Google if possible, but the gender is not specified and should be just the same as the original item."
      ],
      "metadata": {
        "id": "GBZohdhnbRIq"
      },
      "id": "GBZohdhnbRIq"
    },
    {
      "cell_type": "code",
      "source": [
        "preferred_color=\"black\"\n",
        "preferred_brand=\"google\"\n",
        "preferred_gender=\"\""
      ],
      "metadata": {
        "id": "OcCFqAFD1FkT"
      },
      "id": "OcCFqAFD1FkT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the maximum recommended items."
      ],
      "metadata": {
        "id": "TEpgj-4W1o3_"
      },
      "id": "TEpgj-4W1o3_"
    },
    {
      "cell_type": "code",
      "source": [
        "max_recommendations=2"
      ],
      "metadata": {
        "id": "HCrVVIry1tF3"
      },
      "id": "HCrVVIry1tF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define query generator and recommendation engine functions."
      ],
      "metadata": {
        "id": "PvxQx_QVbuPM"
      },
      "id": "PvxQx_QVbuPM"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_string(original_item):\n",
        "    search_query_string=original_item.metadata['description']\n",
        "    search_query_string+= \", Color: \" + (preferred_color if preferred_color != \"\" else original_item.metadata['color'])\n",
        "    search_query_string+= \", Brand: \" + (preferred_brand if preferred_brand != \"\" else original_item.metadata['brand'])\n",
        "    search_query_string+= \", Gender: \" + (preferred_gender if preferred_gender != \"\" else original_item.metadata['gender'])\n",
        "    return search_query_string\n",
        "\n",
        "def get_recommendation(original_item, max_recommendations):\n",
        "    original_item_formatted=format_data([original_item])\n",
        "    search_query_string=get_query_string(original_item)\n",
        "    found_docs = db.similarity_search(\n",
        "        search_query_string,\n",
        "        k=max_recommendations*5,\n",
        "        filter={\"description\": {\"$ne\": original_item.metadata['description']}}\n",
        "    )\n",
        "    found_docs_formatted=format_data(found_docs)\n",
        "    llm_prompt = llm_prompt_template.format(chosen_item=original_item_formatted, available_items=found_docs_formatted, max_recommendations=max_recommendations)\n",
        "    print(f\"{original_item.page_content}:\")\n",
        "    output = llm.invoke(llm_prompt)\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "4OcloDvzxfjm"
      },
      "id": "4OcloDvzxfjm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take 5 products from the dataset and find recommended items for them."
      ],
      "metadata": {
        "id": "2roAPzsYb6gm"
      },
      "id": "2roAPzsYb6gm"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    get_recommendation(data[i*15], max_recommendations)"
      ],
      "metadata": {
        "id": "I_s2GVo_xjpP"
      },
      "id": "I_s2GVo_xjpP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
